# 28. Locks

## 28.1 Locks: The Basic Idea

锁有两种状态：**available（unlocked，free）和acquired（locked，held）**。

当一个线程A调用lock()尝试获得锁，如果没有其他线程锁，那么A线程就会获得锁并进入critical section，称为**owner**。如果其他线程B调用了lock()企图获得同一个锁变量，则B线程不能进入critical section，等待A线程unlock。

线程是一种由程序员创建、由OS调度的实体，将一部分控制权交给了程序员，来保证critical section只能由一个线程运行。

## 28.2 Pthread Locks

在POSIX库中，锁叫**mutex**，因为其用于提供**mutual exclusion**

```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
Pthread_mutex_lock(&lock); // wrapper; exits on failure
balance = balance + 1;
Pthread_mutex_unlock(&lock);
```

POSIX中需要传递一个锁变量来加锁和解锁，因此我们可以用不同的锁来保护不同的变量。这是一种**fine-grained** approach

## 28.3 Building A Lock

CRUX：如何构建一个锁？

## 28.4 Evaluating Locks

我们用以下三个方面来评估锁：

* **mutual exclusion**
* **fairness**：各线程获得锁的机会
* **performance**：使用锁增加的时间开销（没有竞争时？大量竞争时？多个CPU介入时？）

## 28.5 Controlling Interrupts

最早期的一种方法是：禁止interrupts。这种方法很简单，但有很多缺点：

* 需要允许任何调用线程执行privileged操作，OS可能被程序垄断，造成安全隐患。
* 在多处理器上不work
* 可能使interrupt丢失，造成严重系统问题。如CPU错过了磁盘完成了读请求，导致无法唤醒发起读请求的进程。
* 效率低。开关interrupt在现代CPU上执行得很慢。

## 28.6 A Failed Attempt: Just Using Loads/Stores

loads/stores方法：

```c
while(flag == 1)	//TEST the flag
    ;	// spin-wait(do nothing)
flag = 1;
// enter critical section
flag = 0;	// unlock
```

这是个失败的方法：

* **interleaving**: no mutual exclusion，如果TEST过程中被切断，两个进程能同时把flag置1.
* **spin-waiting**: 一个进程需要等待另一个进程解锁，浪费时间，尤其对于单处理器。

## 28.7 Building Working Spin Locks with Test-And-Set

简单的loads/stores不起作用，我们考虑硬件的支持。

一种最简单的方法是**test-and-set（atomic exchange）**：

```c
int TestAndSet(int *old_ptr, int new) {
    int old = *old_ptr;	//fetch old value at old_ptr
    *old_ptr = new;	//store 'new' into old_ptr
    return old;	//return the old value
}
```

Test-And-Set操作是原子化的，它能在test旧值的同时在内存中设置新值。我们以此建立**自旋锁（spin lock）**

```c
typedef struct __lock_t {
    int flag;
} lock_t;

void init(lock_t *lock) {
    // 0: lock is available, 1: lock is held
    lock->flag = 0;
}
void lock(lock_t *lock) {
    while (TestAndSet(&lock->flag, 1) == 1)
        ;	// spin-wait(do nothing)
}
void unlock(lock_t *lock) {
    lock->flag = 0;
}
```

线程反复检查锁变量是否可用，一旦获取了自旋锁，线程会一直保持该锁，直至显式释放。

若在单处理器上运行，需要一个抢占式调度器（**preemptive scheduler**）。

## 28.8 Evaluating Spin Locks

* **correctness**: yes
* **fairness:** no。一个线程可能会永远旋转，导致starvation
* **performance:** 在单处理器上表现不好，但在多处理器上表现较好（线程数约等于CPU数）

## 28.9 Compare-And-Swap

```c
int CompareAndSwap(int *ptr, int expected, int new) {
    int original = *ptr;
    if (original == expected)
    	*ptr = new;
    return original;
}

void lock(lock_t *lock) {
    while (CompareAndSwap(&lock->flag, 0, 1) == 1)
    	; // spin
}
```

如果只是建立一个自旋锁，compare-and-swap方法和test-and-set是等价的。但它在**lock-free synchronization**上有强大作用，会在以后介绍。

## 28.10 Load-Linked and Store-Conditional

在MIPS架构中，使用**load-linked**和**store-conditional**指令来构建锁。

```c
int LoadLinked(int *ptr) {
	return *ptr;
}
int StoreConditional(int *ptr, int value) {
	if (no update to *ptr since LoadLinked to this address) {
	*ptr = value;
		return 1; // success!
	} else {
		return 0; // failed to update
	}
}
```

```c
void lock(lock_t *lock) {
	while (1) {
		while (LoadLinked(&lock->flag) == 1)
			; // spin until it’s zero
		if (StoreConditional(&lock->flag, 1) == 1)
            return; // if set-it-to-1 was a success: all done
		// otherwise: try it all over again
    }
}
void unlock(lock_t *lock) {
	lock->flag = 0;
}
```

## 28.11 Fetch-And-Add

```c
int FetchAndAdd(int *ptr) {
    int old = *ptr;
    *ptr = old + 1;
    return old;
}
```

```c
typedef struct __lock_t {
    int ticket;
    int turn;
} lock_t;
void lock_init(lock_t *lock) {
    lock->ticket = 0;
    lock->turn = 0;
}
void lock(lock_t *lock) {
    int myturn = FetchAndAdd(&lock->ticket);
    while (lock->turn != myturn)
        ;	// spin
}
void unlock(lock_t *lock) {
    lock->turn = lock->turn + 1;
}
```

此方法的优点在于：一旦一个线程被分配了ticket，那么保证了它未来一定会被调度到（只要之前的线程通过了critical section并unlock）；而test-and-set可能会使一些线程永远spin下去（某线程unlock又马上lock）。

## 28.12 Too Much Spinning: What Now?

自旋锁浪费大量时间用来spin（检查锁），尤其对于单处理器。

CRUX：如何避免不必要的旋转？

单凭硬件支持不够解决问题，我们需要OS的支持。

## 28.13 A Simple Approach: Just Yield, Baby

一个简单的方法就是：如果一个线程试图lock()但发现线程已被held，那么就调用yield()这个system call来放弃CPU，从而deschedule自己。

```c
void lock() {
    while (TestAndSet(&flag, 1) == 1)
        	yield();	// give up the CPU
}
```

然而缺点在于：

* 占有锁的线程会在解锁前被打断，切换到其他线程，频繁的上下文切换（round-robin-like）浪费大量CPU资源。
* 没有解决starvation问题

## 28.14 Using Queues: Sleeping Instead Of Spinning

当一个线程发现锁被其他线程持有，可以将其放进一个队列等待，并进入sleep状态；当有锁释放时，再从队列中拿出一个线程将其唤醒。

![image-20211215213116473](<../../.gitbook/assets/image 20211215213116473>)

以上时Solaris中的实现代码，用park()和unpark()来催眠/唤醒线程，使用guard作为自旋锁保护flag和queue操作。

这种方法使得当锁被占有时，任何试图获得锁的线程都会被阻塞，保证了占有锁的线程不会被打断。（使访问critical section的操作成为一个原子操作）

## 28.15 Different OS, Different Support

Linux中futex锁的设计：

```c
void mutex_lock (int*mutex) {
    int v;
    /*Bit 31 was clear, we got the mutex (the fastpath)*/
    if (atomic_bit_test_set (mutex, 31) == 0)
        return;
    atomic_increment (mutex);
    while (1) {
        if (atomic_bit_test_set (mutex, 31) == 0) {
            atomic_decrement (mutex);
            return;
        }
        /*We have to wait
        First make sure the futex value 
        we are monitoring is truly negative (locked).*/
        v =*mutex;
        if (v >= 0)
            continue;
        futex_wait (mutex, v);
    }
}
void mutex_unlock (int*mutex) {
    /*Adding 0x80000000 to counter results in 0 if and
    only if there are not other interested threads*/
    if (atomic_add_zero (mutex, 0x80000000))
        return;
    /*There are other threads waiting for this mutex,
    wake one of them up.*/
    futex_wake (mutex);
}
```

## 28.16 Two-Phase Locks

早期锁有两阶段；现在在Linux中的锁（futex）可以循环自旋。

two-phase locks是一种hybrid approach
